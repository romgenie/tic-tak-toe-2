{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>Goals: exhaustive, deterministic, research-grade tic-tac-toe solver and datasets.</p> <p>Design highlights: canonicalization by dihedral group, strict determinism for reproducibility, CLI for exporting datasets.</p> <p>See other pages for details.</p>"},{"location":"#how-to-cite","title":"How to cite","text":"<p>See <code>CITATION.cff</code> in the repository root or the README for a copy-pastable snippet. Releases are archived on Zenodo; use the DOI badge in the README.</p>"},{"location":"ablations/","title":"Ablations","text":"<p>Add flags such as --canonical-only and --no-augmentation to study the impact of symmetry handling.</p> <p>Recommended comparisons:</p> <ul> <li>canonical_only vs full + augmentation on dataset size and policy distributions</li> <li>normalize_to_move on/off for feature compactness</li> </ul> <p>Write results into metrics.csv and reference them here.</p>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>This page documents typical performance for solver and export operations and how to reproduce locally.</p>"},{"location":"benchmarks/#methodology","title":"Methodology","text":"<ul> <li>Hardware: note CPU model and RAM. Example: Apple M2 Pro, 16GB RAM.</li> <li>OS: macOS 14.x or Ubuntu 22.04.</li> <li>Python: 3.11 or 3.12.</li> <li>NumPy: tested on 1.26.x and 2.x.</li> <li>Environment: <code>pip install -r requirements-lock.txt --require-hashes &amp;&amp; pip install -e .</code> (for archival) or <code>pip install .[dev]</code> for local dev. Optionally add <code>.[parquet]</code> for Parquet runs.</li> </ul> <p>We use <code>pytest-benchmark</code> to time hot paths. Benchmarks are stable and avoid tiny timers via <code>--benchmark-min-time=0.1</code>.</p>"},{"location":"benchmarks/#deterministic-protocol","title":"Deterministic protocol","text":"<p>To keep CPU threading and hashing deterministic across runs, set:</p> <pre><code>export PYTHONHASHSEED=0\nexport MKL_NUM_THREADS=1\nexport OPENBLAS_NUM_THREADS=1\nexport OMP_NUM_THREADS=1\n</code></pre> <p>Then run the benchmarks with a warmup:</p> <pre><code>pytest -q -k benchmark --benchmark-min-time=0.1 --benchmark-warmup=on --benchmark-warmup-iterations=10\n</code></pre>"},{"location":"benchmarks/#reproduce-locally","title":"Reproduce locally","text":"<pre><code>pip install -r requirements-lock.txt --require-hashes\npip install -e .[dev]\n# optional for parquet\npip install .[parquet]\n\npytest -q -k benchmark --benchmark-min-time=0.1\n</code></pre>"},{"location":"benchmarks/#sample-results-indicative","title":"Sample results (indicative)","text":"<ul> <li>Perfect-play solver (enumerate all reachable states, memoized): typically &lt;100 ms.</li> <li>Dataset export (CSV, canonical-only, no augmentation): &lt;500 ms.</li> <li>Dataset export (both CSV+Parquet): slightly higher due to serialization overhead.</li> </ul> <p><code>pytest-benchmark</code> output example:</p> <pre><code>--------------------------------------------------------------------------------------- benchmark: 2 tests --------------------------------------------------------------------------------------\nName (time in ms)                      Min       Max      Mean   StdDev    Median      IQR  Outliers  OPS (Kops/s)  Rounds  Iterations\n-----------------------------------------------------------------------------------------------------------------------------------------------------------\ntest_solver_full_enumeration        45.000    60.000    50.000     3.00    49.500    4.000       2;0           20.0      20           1\ntest_export_small_csv              180.000   260.000   200.000    15.00   198.000   20.000       1;1            5.0      10           1\n-----------------------------------------------------------------------------------------------------------------------------------------------------------\n</code></pre> <p>Numbers vary slightly by machine and Python/NumPy version but are consistently within the same order of magnitude.</p>"},{"location":"benchmarks/#notes","title":"Notes","text":"<ul> <li>All pipelines are pure Python with vectorized components where applicable.</li> <li>CSV order is deterministic, which can add minimal sorting cost but is essential for reproducibility.</li> </ul>"},{"location":"benchmarks/#ci-artifacts","title":"CI artifacts","text":"<p>Automated runs publish raw <code>pytest-benchmark</code> JSON and a small summary tied to:</p> <ul> <li>Git commit</li> <li>OS/arch and Python version</li> <li>NumPy version</li> <li>Environment lock identifiers (hash of requirements-lock.txt and/or conda-lock)</li> </ul> <p>See the CI job artifacts for the current branch. The JSON can be downloaded and compared using <code>pytest-benchmark compare</code>.</p>"},{"location":"cli/","title":"CLI Guide","text":"<p>Examples:</p> <ul> <li>ttt symmetry --board 100020000</li> <li>ttt solve --board 100020000</li> <li>ttt datasets export --out data_raw --canonical-only --no-augmentation --epsilons 0.1 --format csv</li> <li>Streaming: echo \"100020000\" | ttt symmetry --stdin</li> </ul>"},{"location":"data_card/","title":"Tic-Tac-Toe Dataset Card","text":"<ul> <li>Name: ttt_states / ttt_state_actions</li> <li>Version: 1.1.0</li> <li>License: Code is MIT; generated datasets are licensed under CC BY 4.0 unless otherwise noted.</li> </ul>"},{"location":"data_card/#provenance","title":"Provenance","text":"<p>Data are generated deterministically by the packaged perfect-play solver over all reachable Tic-Tac-Toe states. No external data sources are used.</p>"},{"location":"data_card/#generation-pipeline","title":"Generation Pipeline","text":"<ul> <li>Enumerate all reachable states starting from an empty board.</li> <li>Compute solver values (win/draw/loss), optimal moves, depth-to-terminal (DTT), and q-values.</li> <li>Derive features: symmetry metadata, positional heuristics, policy targets, and difficulty signals.</li> <li>Optionally add symmetry augmentation for state-action records.</li> <li>Export CSV and optionally Parquet with a manifest (checksums, schema hash, versions).</li> </ul>"},{"location":"data_card/#schema","title":"Schema","text":"<p>See schema JSON files under each export directory (schema/*.schema.json). Schemas include a <code>$schema</code> field and are versioned implicitly via the <code>dataset_version</code> field in the export manifest.</p>"},{"location":"data_card/#splits","title":"Splits","text":"<p>No train/val/test splits are predefined; the dataset enumerates the full state space. Consumers may define splits deterministically by hashing the canonical form.</p>"},{"location":"data_card/#integrity","title":"Integrity","text":"<p>Each export writes a manifest.json with file checksums (sha256) and schema hashes. Use <code>scripts/verify_export.py</code> to verify integrity.</p>"},{"location":"data_card/#ethical-and-legal","title":"Ethical and Legal","text":"<p>No personal or sensitive data. Fully synthetic.</p>"},{"location":"data_card/#reproducibility","title":"Reproducibility","text":"<p><code>make reproduce-all</code> regenerates the reference artifacts deterministically.</p>"},{"location":"datasets/","title":"Datasets","text":"<p>This page serves as the dataset card for the exported Tic-tac-toe datasets.</p> <p>Motivation: Provide an exact, exhaustive reference dataset derived from a perfect-play solver, suitable for benchmarking learning methods, verifying invariants, and reproducing published results.</p> <p>Composition: Two tables are exported.</p> <ul> <li>ttt_states: one row per reachable state (optionally canonical-only). Includes solver value, plies-to-end, optimal move mask, symmetry info, and rich features.</li> <li>ttt_state_actions: one row per legal action in each non-terminal state; includes Q-values, DTT action-tier, optimality mask, and policy targets (uniform-optimal, soft by decision-time tier, and soft by Q).</li> </ul> <p>Generation: Rows are generated via the in-repo solver and feature pipeline. See Reproducibility for commands and stable checksums.</p> <p>Preprocessing: Only deterministic numerical transforms; no randomness. Optional symmetry augmentation can expand state-action coverage.</p> <p>Features: Positional control, threats, connectivity, pattern strength, phase, and per-cell open-line counts. Policies obey probability constraints and are zero outside legal moves.</p> <p>Potential biases: Tic-tac-toe is trivial; policy mass concentrates on optimal moves. Augmentation changes class balance across action rows.</p> <p>Licensing: Code is MIT. Generated datasets are CC BY 4.0 unless otherwise stated; see README.</p> <p>Intended uses: Teaching, benchmarking, verifying RL targets. Misuses: Treating counts as representative of stochastic games or non-perfect-play agents.</p> <p>Determinism &amp; Manifest: The manifest.json includes row counts, checksums, orbit_size_distribution, terminal_split, parquet_written, and schema hashes. The schemas are emitted under export/schema/*.schema.json and are versioned implicitly via <code>dataset_version</code>.</p>"},{"location":"datasets/#parquet-outputs","title":"Parquet outputs","text":"<p>Parquet is written only when explicitly requested via <code>--format parquet</code> or <code>--format both</code> and when the optional dependencies are installed:</p> <ul> <li>Install extras: <code>pip install .[parquet]</code> (installs pandas and pyarrow).</li> <li>Example: <code>python -m tictactoe.cli datasets export --out data_raw/example --format both --canonical-only</code>.</li> </ul> <p>If the dependencies are missing and you request <code>--format parquet</code>, the command fails early with a clear error. If you request <code>--format both</code>, the export gracefully degrades to CSV-only, writes <code>manifest.json</code>, and sets <code>parquet_written=false</code>.</p>"},{"location":"datasets/#dataset-card","title":"Dataset Card","text":"<ul> <li>License: MIT (matches repository license).</li> <li>Intended use: benchmarking algorithms and verifying invariants; educational demos of perfect play and symmetry.</li> <li>Misuse: inferring properties of stochastic or non-perfect agents; overfitting to trivial game dynamics.</li> <li>Determinism: fully deterministic; re-running with identical args produces byte-identical CSVs; manifest contains schema hashes and checksums.</li> <li>Reproducibility: see <code>docs/repro.md</code> for exact commands and environment notes.</li> <li>Reachable counts: captured in <code>manifest.json</code> (<code>row_counts</code>, <code>terminal_split</code>, <code>orbit_size_distribution</code>).</li> <li>Signatures: per-file SHA-256 in <code>manifest.json/checksums</code>.</li> </ul>"},{"location":"experiments/","title":"Experiments &amp; Reproducibility","text":"<p>Use Make targets:</p> <ul> <li>Quick smoke (&lt; 1 minute): make reproduce-min</li> <li>Full pipeline (longer): make reproduce</li> </ul> <p>Artifacts are written to results/YYYY-MM-DD_HHMM/ with:</p> <ul> <li>MANIFEST.json and MANIFEST.md (config + provenance, lock file hashes)</li> <li>metrics.csv and metrics.json</li> <li>figures/ and logs/</li> <li>export_*/ with dataset CSV/Parquet and manifest.json</li> </ul> <p>Determinism:</p> <ul> <li>Environment seeds set via PYTHONHASHSEED and BLAS threads forced to 1</li> <li>No RNG in solver or dataset generation; epsilon policies are analytic</li> <li>Re-running with identical config yields identical outputs (checksums in manifest)</li> </ul>"},{"location":"repro/","title":"Reproducibility Guide","text":"<p>This project is designed for deterministic, research-grade reproducibility.</p>"},{"location":"repro/#environment","title":"Environment","text":"<ul> <li>Python: 3.11 (CI also tests 3.10 and 3.12)</li> <li>NumPy: 1.26.x and 2.x supported</li> <li>Optional: pandas + pyarrow for Parquet</li> </ul> <p>Install with lock (archival):</p> <pre><code>pip install -r requirements-lock.txt --require-hashes\npip install -e .[dev]\n# Parquet (optional)\npip install .[parquet]\n</code></pre> <p>Conda (using conda-lock):</p> <pre><code># create from platform-specific lock (example for macOS arm64)\nconda create -n ttt --file conda-osx-arm64.lock.txt\nconda activate ttt\npip install -e .\n</code></pre>"},{"location":"repro/#deterministic-flags","title":"Deterministic flags","text":"<p>We set seeds and environment variables to avoid nondeterministic BLAS threading:</p> <ul> <li>PYTHONHASHSEED</li> <li>MKL_NUM_THREADS</li> <li>OPENBLAS_NUM_THREADS</li> <li>OMP_NUM_THREADS</li> </ul> <p>The CLI exposes <code>--deterministic</code> and <code>--seed</code>.</p>"},{"location":"repro/#one-shot-pipeline","title":"One-shot pipeline","text":"<pre><code>make reproduce-all\n</code></pre> <p>This exports datasets (CSV + Parquet), runs multi-seed benchmarks with confidence intervals, and builds the docs.</p> <p>This project aims to be fully reproducible end-to-end: solver, datasets, and checksums.</p>"},{"location":"repro/#quick-start","title":"Quick start","text":"<p>1) Create a Python 3.11+ environment and install the package in editable mode with dev extras. 2) Export the small canonical dataset (CSV) and verify integrity.</p> <p>Example using the included Makefile target:</p> <pre><code>make reproduce-small\n</code></pre> <p>This runs the CLI export with CSV outputs and then executes <code>scripts/verify_export.py</code> to check checksums, row counts, and schema hashes.</p>"},{"location":"repro/#manual-commands","title":"Manual commands","text":"<p>If you prefer to run the steps manually:</p> <pre><code>python -m tictactoe.cli datasets export --out data_clean/small --format csv --canonical-only\npython scripts/verify_export.py data_clean/small\n</code></pre> <p>Expected outputs (tree abbreviated):</p> <pre><code>data_clean/small/\n\u251c\u2500\u2500 manifest.json\n\u251c\u2500\u2500 schema/\n\u2502   \u251c\u2500\u2500 ttt_states.schema.json\n\u2502   \u2514\u2500\u2500 ttt_state_actions.schema.json\n\u251c\u2500\u2500 ttt_states.csv\n\u2514\u2500\u2500 ttt_state_actions.csv\n</code></pre> <p>The verify script will fail with a non-zero exit code on any mismatch.</p>"},{"location":"repro/#notes-on-parquet","title":"Notes on Parquet","text":"<p>Parquet export is optional and requires pandas + pyarrow. Install extras with:</p> <pre><code>pip install .[parquet]\n</code></pre> <p>Use <code>--format parquet</code> or <code>--format both</code> to write Parquet. If you request <code>--format parquet</code> without the dependencies installed, the CLI will raise a clear error. If you request <code>--format both</code> without the dependencies, the export will gracefully degrade to CSV-only and still write <code>manifest.json</code> with <code>parquet_written=false</code>.</p>"},{"location":"repro/#determinism","title":"Determinism","text":"<p>CSV rows are written in a deterministic order (sorted by state, then action) to ensure byte-for-byte reproducibility. The manifest records SHA-256 checksums for every exported artifact.</p>"},{"location":"repro/#reproduce-with-locks","title":"Reproduce with locks","text":"<p>Two paths are supported:</p> <ul> <li>pip with cryptographic hashes: <code>pip install -r requirements-lock.txt --require-hashes</code></li> <li>conda with conda-lock: create env from <code>conda-&lt;platform&gt;.lock.txt</code> (generated and published in releases)</li> </ul> <p>Set env vars for determinism before running:</p> <pre><code>export PYTHONHASHSEED=0\nexport MKL_NUM_THREADS=1\nexport OPENBLAS_NUM_THREADS=1\nexport OMP_NUM_THREADS=1\n</code></pre>"},{"location":"repro/#provenance","title":"Provenance","text":"<p>CI publishes artifacts (datasets, benchmark JSON, SBOM) tied to the commit SHA and lock file hashes. Each dataset export includes a <code>manifest.json</code> with commit, dirty flag, environment lock identifiers, and checksums.</p>"},{"location":"repro/#archival-and-dois","title":"Archival and DOIs","text":"<p>We include a <code>.zenodo.json</code> descriptor in the repo. After cutting a GitHub release, enable Zenodo for this repository to mint a DOI and update the README badge to point to the release DOI. Attach the small reference export produced by <code>make reproduce-small</code> as a release asset to preserve artifacts and checksums alongside the code.</p>"},{"location":"results/","title":"Results","text":"<p>This page aggregates key metrics from results/*/metrics.csv and includes CIs where available.</p> <p>In CI, results are uploaded as artifacts. Locally, see the latest timestamp in results/.</p> <p>(Automated table generation can be added to pull from CSV files.)</p>"},{"location":"results/#latest-run-metrics","title":"Latest run metrics","text":"metric value solve_mean_s 0.019416416995227337 solve_ci95_half_s 0.0 export_elapsed_s 0.3076325839792844 rows_states 765 rows_state_actions 2270"},{"location":"theory/","title":"Theory","text":""},{"location":"theory/#minimax-with-strict-tie-breaks","title":"Minimax with strict tie-breaks","text":"<p>We solve states from the perspective of the side-to-move using exact minimax with memoization. The value v \u2208 {+1, 0, \u22121} denotes win/draw/loss under perfect play. Among moves with equal v we break ties by distance-to-terminal (plies):</p> <ul> <li>Win \u227b Draw \u227b Loss</li> <li>Among wins/draws: prefer the shortest plies-to-end</li> <li>Among losses: prefer the longest plies-to-end (delay the loss)</li> </ul> <p>This induces a total preorder over legal actions. Our solver returns per-action q_values \u2208 {+1,0,\u22121} and dtt_action (distance-to-terminal after taking the action), and the set of optimal_moves obeying the policy above.</p>"},{"location":"theory/#symmetry-group-d4-and-canonicalization","title":"Symmetry group (D4) and canonicalization","text":"<p>Tic-tac-toe on a 3\u00d73 board admits the dihedral-4 (D4) symmetry group with 8 elements: {id, rot90, rot180, rot270, hflip, vflip, d1, d2}. We precompute index mappings for each transformation and use them to:</p> <ul> <li>Canonicalize states by selecting the lexicographically smallest image across all 8 transforms.</li> <li>Remap action indices under symmetry for augmentation and invariance checks.</li> </ul> <p>For a board b and transform g \u2208 D4, let g\u00b7b be the transformed board and g\u00b7a the transformed action index. The solver\u2019s value is invariant: V(g\u00b7b) = V(b); optimal moves map equivariantly: g\u00b7ArgMax(b) = ArgMax(g\u00b7b).</p>"},{"location":"theory/#complexity-and-state-graph","title":"Complexity and state graph","text":"<p>From the empty board, 5478 states are reachable (4520 nonterminal; terminal split: X=626, O=316, draw=16). This is a tiny graph and the exact backward induction + memoization completes in milliseconds on commodity hardware. Our features and datasets are O(#states) and fit comfortably in memory.</p>"},{"location":"api/tictactoe/","title":"API Reference: tictactoe","text":""},{"location":"api/tictactoe/#quick-examples","title":"Quick examples","text":"<p>Solve a position and inspect optimal moves:</p> <pre><code>from tictactoe import solve_state\n\n# board as string: 0 empty, 1 X, 2 O\nboard = \"100020000\"  # simple midgame\nres = solve_state(tuple(int(c) for c in board))\nprint(res[\"value\"], res[\"plies_to_end\"], res[\"optimal_moves\"])  # -&gt; 1/0/-1, dtt, tuple of indices\n</code></pre> <p>Generate a small canonical-only dataset in memory:</p> <pre><code>from tictactoe import solve_all_reachable, extract_board_features, generate_state_action_dataset\n\nsolved = solve_all_reachable()\nstates = [extract_board_features([int(c) for c in k], solved, normalize_to_move=True) for k in solved]\nstate_actions = generate_state_action_dataset(solved, canonical_only=True, epsilons=[0.0, 0.1])\nprint(len(states), len(state_actions))\n</code></pre> <p>Export datasets to disk with a manifest:</p> <pre><code>from pathlib import Path\nfrom tictactoe import ExportArgs, run_export\n\nout = run_export(ExportArgs(out=Path(\"data_raw/example\"), format=\"csv\", canonical_only=True, epsilons=[0.1]))\nprint(out)  # path to manifest.json\n</code></pre> <p>tictactoe package.</p> <p>Core algorithms, symmetry handling, datasets, and a simple CLI.</p> <p>Convenience imports are exposed for common workflows.</p>"},{"location":"api/tictactoe/#tictactoe.extract_board_features","title":"<code>extract_board_features(board, solved_map, lambda_temp=0.5, q_temp=1.0, epsilons=None, normalize_to_move=False)</code>","text":"<p>Extract features for a board.</p> <p>By default, features are computed on the board as given. If normalize_to_move=True, we remap pieces so the side-to-move becomes X=1. Note: Policies and q-values are derived from the original board's solver output. Normalization only swaps labels 1&lt;-&gt;2; legality and q-values align by construction because moves are on indices, not on piece IDs.</p> Source code in <code>src/tictactoe/orchestrator.py</code> <pre><code>def extract_board_features(\n    board: List[int],\n    solved_map: Dict[str, dict],\n    lambda_temp: float = 0.5,\n    q_temp: float = 1.0,\n    epsilons: Optional[List[float]] = None,\n    normalize_to_move: bool = False,\n) -&gt; Dict[str, Any]:\n    \"\"\"Extract features for a board.\n\n    By default, features are computed on the board as given.\n    If normalize_to_move=True, we remap pieces so the side-to-move becomes X=1.\n    Note: Policies and q-values are derived from the original board's solver\n    output. Normalization only swaps labels 1&lt;-&gt;2; legality and q-values align\n    by construction because moves are on indices, not on piece IDs.\n    \"\"\"\n    if epsilons is None:\n        epsilons = [0.1]\n    to_move = 1 if board.count(1) == board.count(2) else 2\n    if normalize_to_move and to_move == 2:\n        # swap X and O labels to make current player X\n        normalized_board = [0 if v == 0 else (1 if v == 2 else 2) for v in board]\n        current_player = 1\n    else:\n        normalized_board = board[:]\n        current_player = to_move\n    x_count, o_count = get_piece_counts(normalized_board)\n    winner_raw = get_winner(board)\n    winner_norm = get_winner(normalized_board)\n    key = serialize_board(board)\n    norm_key = serialize_board(normalized_board)\n    reachable = key in solved_map\n\n    if reachable:\n        sol = solved_map[key]\n        value_current = sol[\"value\"]\n        plies_to_end = sol[\"plies_to_end\"]\n        optimal_moves = set(sol[\"optimal_moves\"])\n        qvals = list(sol[\"q_values\"])\n        dtt_a = list(sol[\"dtt_action\"])\n        policy_targets = build_policy_targets(\n            normalized_board, sol, lambda_temp=lambda_temp, q_temp=q_temp\n        )\n        pol_uniform = policy_targets[\"policy_optimal_uniform\"]\n        pol_soft = policy_targets[\"policy_soft_dtt\"]\n        pol_soft_q = policy_targets[\"policy_soft_q\"]\n        eps_policies = {}\n        for eps in epsilons:\n            tag = f\"{int(round(eps*100)):03d}\"\n            eps_policies[tag] = epsilon_policy_distribution(normalized_board, sol, eps)\n        pol_entropy = -sum(p * np.log(p + 1e-10) for p in pol_uniform if p &gt; 0)\n        pol_soft_dtt_entropy = -sum(p * np.log(p + 1e-10) for p in pol_soft if p &gt; 0)\n        child_tiers = {\n            \"child_wins\": sum(1 for v in qvals if v == +1),\n            \"child_draws\": sum(1 for v in qvals if v == 0),\n            \"child_losses\": sum(1 for v in qvals if v == -1),\n        }\n        difficulty = difficulty_score(sol)\n        # optional: compute reply branching factor as the average number of\n        # legal replies for the opponent after optimal moves. Keep lightweight\n        # and deterministic. If no optimal moves, 0.0. Terminal children\n        # contribute 0 by definition (no replies).\n        legal_reply_counts: List[int] = []\n        for mv in optimal_moves:\n            child = board[:]\n            child[mv] = 1 if board.count(1) == board.count(2) else 2\n            if get_winner(child) != 0 or is_draw(child):\n                legal_reply_counts.append(0)\n            else:\n                legal_reply_counts.append(sum(1 for v in child if v == 0))\n        reply_branching = (\n            float(sum(legal_reply_counts) / len(legal_reply_counts)) if legal_reply_counts else 0.0\n        )\n    else:\n        value_current = None\n        plies_to_end = None\n        optimal_moves = set()\n        qvals = [None] * 9\n        dtt_a = [None] * 9\n        pol_uniform = [None] * 9\n        pol_soft = [None] * 9\n        pol_soft_q = [None] * 9\n        eps_policies = {}\n        pol_entropy = None\n        pol_soft_dtt_entropy = None\n        child_tiers = {\"child_wins\": 0, \"child_draws\": 0, \"child_losses\": 0}\n        difficulty = 0.0\n        reply_branching = 0.0\n\n    sym = symmetry_info(board)\n    legal = [normalized_board[i] == 0 for i in range(9)]\n    best_mask = [(i in optimal_moves) for i in range(9)] if reachable else [False] * 9\n    cell_pot = calculate_cell_line_potentials(normalized_board)\n\n    # Extended positional/strategic features (deterministic and cheap)\n    # Use the normalized_board for player-relative metrics\n    x_threats = calculate_line_threats(normalized_board, 1)\n    o_threats = calculate_line_threats(normalized_board, 2)\n    x_conn = calculate_connectivity(normalized_board, 1)\n    o_conn = calculate_connectivity(normalized_board, 2)\n    control = calculate_control_metrics(normalized_board)\n    x_patterns = calculate_pattern_strength(normalized_board, 1)\n    o_patterns = calculate_pattern_strength(normalized_board, 2)\n    game_phase = calculate_game_phase(normalized_board)\n    x_two_open = count_two_in_row_open(normalized_board, 1)\n    o_two_open = count_two_in_row_open(normalized_board, 2)\n\n    features: Dict[str, Any] = {\n        \"board_state\": key,\n        \"normalized_board_state\": norm_key,\n        \"swapped_color\": int(normalize_to_move and to_move == 2),\n        \"x_count\": x_count,\n        \"o_count\": o_count,\n        \"empty_count\": normalized_board.count(0),\n        \"move_number\": x_count + o_count,\n        \"current_player\": current_player,\n        \"is_terminal\": winner_raw != 0 or is_draw(board),\n        \"winner\": winner_raw,\n        \"winner_normalized\": winner_norm,\n        \"is_draw\": is_draw(board),\n        \"is_valid\": is_valid_state(board),\n        \"reachable_from_start\": reachable,\n        \"canonical_form\": sym[\"canonical_form\"],\n        \"canonical_op\": sym[\"canonical_op\"],\n        \"orbit_size\": sym[\"orbit_size\"],\n        \"horizontal_symmetric\": sym[\"horizontal_symmetric\"],\n        \"vertical_symmetric\": sym[\"vertical_symmetric\"],\n        \"diagonal_symmetric\": sym[\"diagonal_symmetric\"],\n        \"rotational_symmetric\": sym[\"rotational_symmetric\"],\n        \"any_symmetric\": sym[\"any_symmetric\"],\n        \"orbit_index\": sym[\"orbit_index\"],\n        \"value_current\": value_current,\n        \"plies_to_end\": plies_to_end,\n        \"optimal_moves_count\": len(optimal_moves),\n        \"optimal_policy_entropy\": pol_entropy,\n        \"policy_soft_dtt_entropy\": pol_soft_dtt_entropy,\n        \"policy_soft_q_entropy\": (\n            -sum(p * np.log(p + 1e-10) for p in pol_soft_q if p &gt; 0) if reachable else None\n        ),\n        # Scalar difficulty per state; 0.0 when not reachable\n        \"difficulty_score\": difficulty,\n        \"reply_branching_factor\": reply_branching,\n        **child_tiers,\n        # control metrics (symmetric)\n        **control,\n        # player-relative threats/connectivity/patterns\n        \"x_row_threats\": x_threats[\"row_threats\"],\n        \"x_col_threats\": x_threats[\"col_threats\"],\n        \"x_diag_threats\": x_threats[\"diag_threats\"],\n        \"x_total_threats\": x_threats[\"total_threats\"],\n        \"o_row_threats\": o_threats[\"row_threats\"],\n        \"o_col_threats\": o_threats[\"col_threats\"],\n        \"o_diag_threats\": o_threats[\"diag_threats\"],\n        \"o_total_threats\": o_threats[\"total_threats\"],\n        \"x_connected_pairs\": x_conn[\"connected_pairs\"],\n        \"x_total_connections\": x_conn[\"total_connections\"],\n        \"x_isolated_pieces\": x_conn[\"isolated_pieces\"],\n        \"x_cluster_count\": x_conn[\"cluster_count\"],\n        \"x_largest_cluster\": x_conn[\"largest_cluster\"],\n        \"o_connected_pairs\": o_conn[\"connected_pairs\"],\n        \"o_total_connections\": o_conn[\"total_connections\"],\n        \"o_isolated_pieces\": o_conn[\"isolated_pieces\"],\n        \"o_cluster_count\": o_conn[\"cluster_count\"],\n        \"o_largest_cluster\": o_conn[\"largest_cluster\"],\n        \"x_open_lines\": x_patterns[\"open_lines\"],\n        \"x_semi_open_lines\": x_patterns[\"semi_open_lines\"],\n        \"x_blocked_lines\": x_patterns[\"blocked_lines\"],\n        \"x_potential_lines\": x_patterns[\"potential_lines\"],\n        \"o_open_lines\": o_patterns[\"open_lines\"],\n        \"o_semi_open_lines\": o_patterns[\"semi_open_lines\"],\n        \"o_blocked_lines\": o_patterns[\"blocked_lines\"],\n        \"o_potential_lines\": o_patterns[\"potential_lines\"],\n        \"x_two_in_row_open\": x_two_open,\n        \"o_two_in_row_open\": o_two_open,\n        \"game_phase\": game_phase,\n    }\n\n    for i in range(9):\n        features[f\"cell_{i}\"] = normalized_board[i]\n        features[f\"legal_{i}\"] = int(legal[i])\n        features[f\"best_{i}\"] = int(best_mask[i])\n        features[f\"q_value_{i}\"] = qvals[i]\n        features[f\"dtt_action_{i}\"] = dtt_a[i]\n        features[f\"canonical_action_map_{i}\"] = apply_action_transform(i, sym[\"canonical_op\"])\n        features[f\"policy_uniform_{i}\"] = pol_uniform[i] if reachable else None\n        features[f\"policy_soft_{i}\"] = pol_soft[i] if reachable else None\n        features[f\"policy_soft_q_{i}\"] = pol_soft_q[i] if reachable else None\n        for tag, pol in eps_policies.items() if reachable else []:\n            features[f\"epsilon_policy_{tag}_{i}\"] = pol[i]\n        features[f\"x_cell_open_lines_{i}\"] = cell_pot[\"x_cell_open_lines\"][i]\n        features[f\"o_cell_open_lines_{i}\"] = cell_pot[\"o_cell_open_lines\"][i]\n\n    return features\n</code></pre>"},{"location":"api/tictactoe/#tictactoe.solve_all_reachable","title":"<code>solve_all_reachable()</code>","text":"<p>Enumerate and solve all states reachable from the empty board.</p> Source code in <code>src/tictactoe/solver.py</code> <pre><code>def solve_all_reachable() -&gt; dict:\n    \"\"\"Enumerate and solve all states reachable from the empty board.\"\"\"\n    all_nodes = {}\n    q = deque()\n    start = tuple([0] * 9)\n    q.append(start)\n    seen = {start}\n    while q:\n        s = q.popleft()\n        all_nodes[s] = True\n        if winner_t(s) != 0 or is_draw_t(s):\n            continue\n        p = current_player_t(s)\n        for mv in legal_moves(s):\n            child = apply_move_t(s, mv, p)\n            if child not in seen:\n                seen.add(child)\n                q.append(child)\n    solved = {}\n    for s in all_nodes:\n        res = solve_state(s)\n        solved[\"\".join(map(str, s))] = res\n    return solved\n</code></pre>"}]}